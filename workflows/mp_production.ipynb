{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from shutil import copyfile\n",
    "import os, subprocess, pipes, re, json, glob, yaml, sys\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from fireworks.core.launchpad import LaunchPad\n",
    "from boltons.tbutils import ParsedException\n",
    "from pymongo import MongoClient\n",
    "GARDEN = '/global/projecta/projectdirs/matgen/garden/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad = LaunchPad.from_file('my_launchpad.yaml')\n",
    "lpad.fireworks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "materials_prod_config_path = os.path.join('materials_db_prod.yaml')\n",
    "materials_prod_config_file = open(materials_prod_config_path, 'r')\n",
    "config = yaml.load(materials_prod_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = MongoClient(config['host'], config['port'], j=False)\n",
    "db_jp = conn[config['db']]\n",
    "db_jp.authenticate(config['user_name'], config['password'])\n",
    "db_jp.materials.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vasp_config = json.load(open('tasks_db.json'))\n",
    "vasp_conn = MongoClient(vasp_config['host'], vasp_config['port'], j=False)\n",
    "db_vasp = vasp_conn[vasp_config['database']]\n",
    "db_vasp.authenticate(vasp_config['readonly_user'], vasp_config['readonly_password'])\n",
    "db_vasp.tasks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat tasks_db.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_categories(cats):\n",
    "    c = Counter(dict((k, len(v)) for k, v in cats.items()))\n",
    "    top10 = c.most_common(10)\n",
    "    total = 0\n",
    "    for k,v in top10:\n",
    "        print(v, '\\t', cats[k], '\\t', k)\n",
    "        total += v\n",
    "    print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [\"RUNNING\", \"WAITING\", \"FIZZLED\", \"READY\", \"COMPLETED\", \"RESERVED\", \"ARCHIVED\", \"DEFUSED\", \"PAUSED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general: fizzled workflows and according list of fireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_remarks = [\n",
    "    \"new ICSD batch\", \"Pauling file\", \"Heusler ABC2 phases\",\n",
    "    \"proton conducting materials for fuel cells\", \"solid solution metal\", \"solid solution oxide\", \"intermetallic\",\n",
    "    \"CNGMD Nitrides\", \"MAGICS calculation of band structures of 2D TMDC stacked heterostructures\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fw_ids for user-submitted workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_query = {\"spec.task_type\": \"Add to SNL database\", \"spec.snl.about.remarks\": \"MP user submission\"}\n",
    "user_query = {\"spec.task_type\": \"Add to SNL database\", \"spec.snl.about.remarks\": user_remarks[-3]}\n",
    "fw_ids_user = lpad.fireworks.find(user_query, {'fw_id': 1, '_id': 0}).distinct('fw_id')\n",
    "print(len(fw_ids_user), 'user-submitted workflows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pause controller, defuse/fizzle workflows with >20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for root_fw_id in fw_ids_user:\n",
    "#     print(root_fw_id)\n",
    "    wflows = list(lpad.workflows.find({'nodes': root_fw_id}, ['nodes', 'state', 'links']))\n",
    "    if len(wflows) > 1:\n",
    "        print('\\tmultiple workflows for', root_fw_id)\n",
    "        continue\n",
    "    wf = wflows[0]\n",
    "    fws = {}\n",
    "    for fw in lpad.fireworks.find(\n",
    "        {'fw_id': {'$in': wf['nodes']}}, {'fw_id': 1, 'spec.task_type': 1, 'state': 1, '_id': 0}\n",
    "    ):\n",
    "        fw_id = fw.pop('fw_id')\n",
    "        fws[fw_id] = fw\n",
    "\n",
    "    for fw_id, fw in fws.items():\n",
    "        # pause controller tasks (problems with band structure calcs)\n",
    "#         if fw['spec']['task_type'] == 'Controller: add Electronic Structure v2' and \\\n",
    "#         fw['state'] in ['WAITING', 'READY']:\n",
    "#             lpad.pause_fw(fw_id)\n",
    "#             fws[fw_id]['state'] = 'PAUSED'\n",
    "#             print('\\tpaused', fw_id)\n",
    "        # defuse workflows with more than 20 tasks (endless SO?)\n",
    "        if wf['state'] != 'COMPLETED' and len(wf['nodes']) > 20 and \\\n",
    "        fw['state'] not in ['COMPLETED', 'DEFUSED', 'PAUSED']:\n",
    "            try:\n",
    "                lpad.defuse_fw(fw_id)\n",
    "                fws[fw_id]['state'] = 'DEFUSED'\n",
    "                print('\\tdefused', fw_id)\n",
    "            except Exception as ex:\n",
    "                print('\\tdefusing', fw_id, 'failed:', str(ex))\n",
    "                lpad.fireworks.update_one({'fw_id': fw_id}, {\"$set\":{\"state\":\"FIZZLED\"}})                \n",
    "                print('\\t', fw_id, 'set to FIZZLED')\n",
    "            \n",
    "    if fws[root_fw_id]['state'] == 'COMPLETED':\n",
    "        current_fw_id = root_fw_id\n",
    "        while 1:\n",
    "            daughters = wf['links'][str(current_fw_id)]\n",
    "            if not daughters:\n",
    "                raise ValueError('why did I get here?')\n",
    "            if len(daughters) == 1:\n",
    "                #print('daughter:', current_fw_id, daughters[0], fws[daughters[0]]['spec']['task_type'])\n",
    "                if fws[daughters[0]]['spec']['task_type'] == 'Controller: add Electronic Structure v2':\n",
    "                    counter[fws[current_fw_id]['state']] += 1\n",
    "                    break\n",
    "                else:\n",
    "                    current_fw_id = daughters[0]\n",
    "            else:\n",
    "                so_task_found = False\n",
    "                for daughter in daughters:\n",
    "                    if fws[daughter]['spec']['task_type'] == 'GGA optimize structure (2x)':\n",
    "                        current_fw_id = daughter\n",
    "                        so_task_found = True\n",
    "                        break\n",
    "                if not so_task_found:\n",
    "                    raise ValueError('SO task not found!')\n",
    "    else:\n",
    "        counter[fws[root_fw_id]['state']] += 1\n",
    "\n",
    "print(counter)\n",
    "print('total =', sum(counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw_fws = {}\n",
    "for state in states:\n",
    "    vw_fws[state] = list(lpad.fireworks.find({\n",
    "        \"state\": state, \"$or\": [\n",
    "            {\"spec.snl.about.remarks\": \"solid solution metal\"},\n",
    "            {\"spec.mpsnl.about.remarks\": \"solid solution metal\"}\n",
    "        ]\n",
    "    }, ['spec.task_type', 'fw_id']))\n",
    "    if vw_fws[state]:\n",
    "        print(state, len(vw_fws[state]))\n",
    "        if state in ['RUNNING', 'READY', 'RESERVED']:\n",
    "            print(Counter(fw['spec']['task_type'] for fw in vw_fws[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prioritized user-submitted \"Add to SNL\" tasks to get duplicate checking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "priority_user_query = {\n",
    "    \"$and\": [\n",
    "        {\"$or\": [\n",
    "            {\"spec.snl.about.remarks\": {\"$in\": [\"MP user submission\"], \"$nin\": user_remarks}},\n",
    "            {\"spec.mpsnl.about.remarks\": {\"$in\": [\"MP user submission\"], \"$nin\": user_remarks}},    \n",
    "        ]}, {\"$or\": [\n",
    "            {\"spec.prev_vasp_dir\": {\"$exists\": 0}},\n",
    "            {\"spec.prev_vasp_dir\": {\"$regex\": \"/oasis/\"}},        \n",
    "        ]}      \n",
    "    ]\n",
    "}\n",
    "priority_user_fws = {}\n",
    "for state in states:\n",
    "    if state == 'READY':\n",
    "        state_query = {'state': state}\n",
    "        state_query.update(priority_user_query)\n",
    "        priority_user_fws[state] = list(lpad.fireworks.find(state_query, {\n",
    "                    \"fw_id\": 1, \"spec.task_type\": 1, \"spec.prev_vasp_dir\": 1, \"_id\": 0}))\n",
    "        nr_fws = len(priority_user_fws[state])\n",
    "        if nr_fws > 0:\n",
    "            add_to_snl = []\n",
    "            for d in priority_user_fws[state]:\n",
    "                if d['spec']['task_type'] == 'Add to SNL database':\n",
    "                    add_to_snl.append(d['fw_id'])\n",
    "            print(' '.join(map(str, add_to_snl)))\n",
    "            print('{} {} user-submitted XSEDE tasks'.format(nr_fws, state))\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### percentage of workflows in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 118151 = {Ti,Zr,Hf}-Zn-N piezoelectricity study -> ALL COMPLETED 2017-01-24\n",
    "# 114781 = Kitchaev Workflows\n",
    "# 115780 = Heusler ABC2 phases\n",
    "# 89070 = Silvana Botti Perovskite Structures\n",
    "submission_group_id = 89070\n",
    "query = {'nodes': {'$in': fw_ids_user}}\n",
    "# if user_query[\"spec.snl.about.remarks\"] == \"MP user submission\":\n",
    "#     print('FYI: only looking at workflows with submission_group_id', submission_group_id)\n",
    "#     query.update({'metadata.submission_group_id': submission_group_id})\n",
    "wflows = {}\n",
    "total_wflows = float(lpad.workflows.find(query).count())\n",
    "wflows_projection = {'fw_states': 1, 'parent_links': 1, 'links': 1, 'nodes': 1, '_id': 0, 'state': 1}\n",
    "for state in states:\n",
    "    state_query = {'state': state}\n",
    "    state_query.update(query)\n",
    "    wflows[state] = list(lpad.workflows.find(state_query, wflows_projection))\n",
    "    nr_wflows = len(wflows[state])\n",
    "    if nr_wflows > 0:\n",
    "        if state == 'FIZZLED':\n",
    "            print([wf['nodes'][0] for wf in wflows[state]])\n",
    "        wflows_fraction =  nr_wflows / total_wflows\n",
    "        print('{} {} workflows ({:.1f}%)'.format(nr_wflows, state, wflows_fraction*100.))\n",
    "print(int(total_wflows), 'workflows in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of first fizzled fw_id in each workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_root_node(wflow):\n",
    "    # wflow['nodes'][0] is not necessarily the root node!\n",
    "    parent_links_keys = wflow['parent_links'].keys()\n",
    "    for node in wflow['nodes']:\n",
    "        if str(node) in parent_links_keys:\n",
    "            continue\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = 'FIZZLED' # workflow state\n",
    "rerun_fws = []\n",
    "fw_ids_state = {}\n",
    "for wflow in wflows[state]:\n",
    "    root_fw_id = find_root_node(wflow)\n",
    "    # decend links until fizzled firework found\n",
    "    fw_id = root_fw_id\n",
    "    check_states = [state] if state != 'RUNNING' else ['READY', 'RESERVED']\n",
    "    while 1:\n",
    "        current_state = wflow['fw_states'][str(fw_id)]\n",
    "        if current_state == 'RUNNING':\n",
    "            print(fw_id, 'is RUNNING -> probably need to do `lpad rerun_fws -i {}`'.format(fw_id))\n",
    "            break\n",
    "        if current_state in check_states:\n",
    "            task_type = lpad.fireworks.find_one({'fw_id': fw_id}, {'spec.task_type': 1})['spec']['task_type']\n",
    "            if task_type not in fw_ids_state:\n",
    "                fw_ids_state[task_type] = [int(fw_id)]\n",
    "            else:\n",
    "                fw_ids_state[task_type].append(int(fw_id))\n",
    "            alt_state = lpad.fireworks.find_one({'fw_id': fw_id}, {'state': 1, '_id': 0})['state']\n",
    "            if alt_state == 'RESERVED':\n",
    "                rerun_fws.append(str(fw_id))\n",
    "            break\n",
    "        # if multiple children use non-waiting fw\n",
    "        children = wflow['links'][str(fw_id)]\n",
    "        for child in children:\n",
    "            if wflow['fw_states'][str(child)] != 'WAITING':\n",
    "                fw_id = child\n",
    "if rerun_fws:\n",
    "    print('lpad rerun_fws -i', ' '.join(rerun_fws))\n",
    "for k,v in fw_ids_state.items():\n",
    "    #if 'GGA' not in k: continue\n",
    "    print(k, v)\n",
    "#     for fw_id in v:\n",
    "#         launches = lpad.launches.find({'fw_id': fw_id}, {'launch_dir': 1})\n",
    "#         for launch in launches:\n",
    "#             if not 'oasis' in launch['launch_dir']:\n",
    "#                 print ('\\t', fw_id, launch['launch_dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of incomplete fireworks in RUNNING workflows for fworker query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw_ids_incomplete = {}\n",
    "for wflow in wflows['RUNNING']:\n",
    "    for fw_id, fw_state in wflow['fw_states'].items():\n",
    "        if fw_state != 'COMPLETED':\n",
    "            if fw_state not in fw_ids_incomplete:\n",
    "                fw_ids_incomplete[fw_state] = [int(fw_id)]\n",
    "            else:\n",
    "                fw_ids_incomplete[fw_state].append(int(fw_id))\n",
    "print(fw_ids_incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for d in lpad.workflows.find({'nodes': {'$in':[1370872,1566138,1566120,1566104,1566099,1567504,1567491,1563287,1652717]}}, {'_id': 0, 'nodes': 1}):\n",
    "    nodes += d['nodes']\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of first fireworks for fizzled workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = {'fw_id': {'$in': [fw_id for fw_id in fw_ids_state.values()]}} # FIXME\n",
    "projection = {'fw_id': 1, 'launches': 1, '_id': 0}\n",
    "fws = list(lpad.fireworks.find(query, projection))\n",
    "assert(len(fws) == len(wflows[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of uniform tasks/fw_ids for projections in BoltzTraP builder (VASP DB insertion reruns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('task_fw_ids_wBS.json', 'r') as f:\n",
    "    task_fw_ids_wBS = json.loads(f.read())\n",
    "print(len(task_fw_ids_wBS), 'tasks already checked for projections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vasp_fw_ids = []\n",
    "for fw_id in task_fw_ids_wBS.itervalues():\n",
    "    wf = lpad.workflows.find_one({'nodes': fw_id}, {'_id': 0, 'links': 1})\n",
    "    for daughter in wf['links'][str(fw_id)]:\n",
    "        fw = lpad.fireworks.find_one(\n",
    "            {'fw_id': daughter, 'spec.task_type': 'VASP db insertion'}, {'fw_id': 1, '_id': 0}\n",
    "        )\n",
    "        if fw:\n",
    "            vasp_fw_ids.append(fw['fw_id'])\n",
    "            break\n",
    "len(vasp_fw_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad.fireworks.update_many(\n",
    "    {'fw_id': {'$in': vasp_fw_ids}},\n",
    "    {'$unset' : {'spec._tasks.0.update_duplicates' : 1}}\n",
    ").raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    lpad.fireworks.find({'state': 'READY', 'spec.task_type': 'VASP db insertion'}).count(),\n",
    "    'VASP db insertion tasks ready to run'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('task_fw_ids_woBS.json', 'r') as f:\n",
    "    task_fw_ids_woBS = json.loads(f.read())\n",
    "print(len(task_fw_ids_woBS), 'tasks without BS')\n",
    "fws = lpad.fireworks.find(\n",
    "    {'fw_id': {'$in': task_fw_ids_woBS.values()}, 'state': 'COMPLETED'}, \n",
    "    {'launches': 1, 'fw_id': 1, '_id': 0}\n",
    ")\n",
    "print('{}/{} fireworks found'.format(fws.count(), len(task_fw_ids_woBS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### launch directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for XSEDE: rsync to Mendel from\n",
    "\n",
    "- /oasis/projects/nsf/csd436/phuck/garden\n",
    "- /oasis/scratch/comet/phuck/temp_project\n",
    "\n",
    "`rsync -avz block_* mendel:/global/projecta/projectdirs/matgen/garden/`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fws_info = {}\n",
    "no_launches_found = []\n",
    "\n",
    "for fw in fws:\n",
    "    if not fw['launches']:\n",
    "        no_launches_found.append(fw['fw_id'])\n",
    "        continue\n",
    "\n",
    "    launch_id = fw['launches'][-1]\n",
    "    launch = lpad.launches.find_one({'launch_id': launch_id}, {'launch_dir': 1, '_id': 0})\n",
    "    launch_dir = launch['launch_dir']\n",
    "    launch_dir_exists = False\n",
    "\n",
    "    for fw_id, fw_info in fws_info.items():\n",
    "        if launch_dir == fw_info['launch_dir']:\n",
    "            launch_dir_exists = True\n",
    "            break\n",
    "    \n",
    "    if launch_dir_exists:\n",
    "        if 'duplicates' in fws_info[fw_id]:\n",
    "            fws_info[fw_id]['duplicates'].append(fw['fw_id'])\n",
    "        else:\n",
    "            fws_info[fw_id]['duplicates'] = [fw['fw_id']]\n",
    "        continue\n",
    "    \n",
    "    fws_info[fw['fw_id']] = {'launch_dir': launch_dir.strip()}\n",
    "\n",
    "if len(no_launches_found) > 0:\n",
    "    print('launches not found for', len(no_launches_found), 'fireworks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_duplicates = 0\n",
    "for fw_id, fw_info in fws_info.iteritems():\n",
    "    if 'duplicates' in fw_info:\n",
    "        nr_duplicates += len(fw_info['duplicates'])\n",
    "print(nr_duplicates, '/', len(fws), 'workflows have duplicate launch_dirs =>',\n",
    "      len(fws)-nr_duplicates, 'unique launch_dirs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dest_blocks(s):\n",
    "    a = s.strip().split('/block_')\n",
    "    if len(a) == 2:\n",
    "        return [a[0], 'block_'+a[1]]\n",
    "    a = s.strip().split('/launcher_')\n",
    "    return [a[0], 'launcher_'+a[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_launchdirs():\n",
    "    for fw_id, fw_info in fws_info.iteritems():\n",
    "        launch_dir = fw_info['launch_dir']\n",
    "        if not os.path.exists(launch_dir):\n",
    "            dest, block = get_dest_blocks(launch_dir)\n",
    "            launch_dir = os.path.join(GARDEN, block)\n",
    "            fw_info['launch_dir'] = launch_dir if os.path.exists(launch_dir) else None\n",
    "            # 'compgen -G \"$i/*.out\" >> ~/launchdirs_exist_outfiles.txt; '\n",
    "            # 'compgen -G \"$i/*.error\" >> ~/launchdirs_exist_outfiles.txt; '\n",
    "    print('found {}/{} launch directories'.format(\n",
    "        sum([bool(fw_info['launch_dir']) for fw_info in fws_info.itervalues()]), len(fws_info)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_launchdirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze log output of fizzled workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scan for error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_path(extension, dirlist):\n",
    "    for fstr in dirlist:\n",
    "        fn, ext = os.path.splitext(os.path.basename(fstr))\n",
    "        if fn+ext == 'vasp.out':\n",
    "            continue\n",
    "        if ext == extension:\n",
    "            return fstr\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scan_errors_warnings(f):\n",
    "    for line in f.readlines():\n",
    "        line_lower = line.strip().lower()\n",
    "        if 'error:' in line_lower or 'warning:' in line_lower:\n",
    "            return line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fw_id, fw_info in tqdm(fws_info.items()):\n",
    "    fw_info['errors'] = []\n",
    "    \n",
    "    if 'remote_dir' not in fw_info:\n",
    "        fw_info['errors'].append('remote_dir not found')\n",
    "        continue\n",
    "    local_dir = fw_info['local_dir']\n",
    "    if not os.path.exists(local_dir):\n",
    "        fw_info['errors'].append('local_dir not found')\n",
    "        continue\n",
    "    ls = glob.glob(os.path.join(local_dir, '*'))\n",
    "    if not ls:\n",
    "        fw_info['errors'].append('no files found in local_dir')\n",
    "        continue\n",
    "\n",
    "    error_file = get_file_path('.error', ls)\n",
    "    if error_file is not None:\n",
    "        # look for a traceback in *.error\n",
    "        with open(error_file, 'r') as f:\n",
    "            fcontent = f.read()\n",
    "            match = re.search('Traceback((.+\\n)+)Traceback', fcontent)\n",
    "            if not match:\n",
    "                match = re.search('Traceback((.+\\n)+)INFO', fcontent)\n",
    "                if not match:\n",
    "                    match = re.search('Traceback((.+\\n)+)$', fcontent)\n",
    "            if match:\n",
    "                fw_info['errors'].append('Traceback'+match.group(1))\n",
    "            else:\n",
    "                scan = scan_errors_warnings(f)\n",
    "                if scan:\n",
    "                    fw_info['errors'].append(scan)\n",
    "\n",
    "    # look into .out file\n",
    "    out_file = get_file_path('.out', ls)\n",
    "    with open(out_file, 'r') as f:\n",
    "        scan = scan_errors_warnings(f)\n",
    "        if scan:\n",
    "            fw_info['errors'].append(scan)\n",
    "\n",
    "    # look into vasp.out\n",
    "    vasp_out = os.path.join(local_dir, 'vasp.out')\n",
    "    if os.path.exists(vasp_out):\n",
    "        with open(vasp_out, 'r') as f:\n",
    "            vasp_out_tail = f.readlines()[-1].strip()\n",
    "            fw_info['errors'].append(' -- '.join(['vasp.out', vasp_out_tail]))\n",
    "\n",
    "# FIXME .out and .error for non-reservation mode one directory up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### categorize errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_fw_to_category(fw_id, key, cats):\n",
    "    if key in cats:\n",
    "        cats[key].append(fw_id)\n",
    "    else:\n",
    "        cats[key] = [fw_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for fw_id, fw_info in fws_info.iteritems():\n",
    "    if not fw_info['errors']:\n",
    "        add_fw_to_category(fw_id, 'no errors parsed', categories)\n",
    "        continue\n",
    "    for error in fw_info['errors']:\n",
    "        if 'remote_dir' in error or 'local_dir' in error:\n",
    "            add_fw_to_category(fw_id, error, categories)\n",
    "        elif error.startswith('Traceback'):       \n",
    "            exc = ParsedException.from_string(error)\n",
    "            msg = exc.exc_msg[:50]\n",
    "            match = re.search('errors reached: (.*)', msg)\n",
    "            if match:\n",
    "                msg = match.group(1)\n",
    "            key = ' -- '.join([exc.exc_type, msg])\n",
    "            lineno = exc.frames[-1]['lineno']\n",
    "            key = ' -- '.join([key, os.path.basename(exc.source_file) + '#' + lineno])\n",
    "            add_fw_to_category(fw_id, key, categories)\n",
    "        else:\n",
    "            match = re.search('{(.*)}', error) # matches dictionary\n",
    "            if match:\n",
    "                dstr = '{' + match.group(1) + '}'\n",
    "                dstr = dstr.replace(\"u'\", '\"').replace(\"'\", '\"')\n",
    "                dstr = re.sub('{\"handler\": (.*), \"errors\"', '{\"handler\": \"\\g<1>\", \"errors\"', dstr)\n",
    "                try:\n",
    "                    d = json.loads(dstr)\n",
    "                except:\n",
    "                    add_fw_to_category(fw_id, 'looks like dict but could not decode', categories)\n",
    "                else:\n",
    "                    if 'handler' in d and 'errors' in d:\n",
    "                        if '<' in d['handler']:\n",
    "                            match = re.search('custodian\\.vasp\\.handlers\\.(.*) object', d['handler'])\n",
    "                            if match:\n",
    "                                d['handler'] = match.group(1)\n",
    "                            else:\n",
    "                                raise ValueError('custodian.vasp.handlers not matched')\n",
    "                        add_fw_to_category(fw_id, d['handler'], categories)\n",
    "                    elif 'action' in d:\n",
    "                        add_fw_to_category(fw_id, 'action', categories)\n",
    "                    else:\n",
    "                        add_fw_to_category(fw_id, 'found dict but not handler or action error', categories)\n",
    "            else:\n",
    "                add_fw_to_category(fw_id, error, categories)\n",
    "        break # only look at first error\n",
    "print_categories(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fws_info[1564191]['remote_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad.fireworks.find_one({'fw_id': 1564191}, {'spec._priority': 1, 'state': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad.fireworks.find_one({'fw_id': 1285769}, {'spec._priority': 1, 'state': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad.fireworks.find_one({'fw_id': 1399045}, {'spec._priority': 1, 'state': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kitchaev submissions: mp-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('mpcomplete_kitchaev.json', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_last_node(wflow):\n",
    "    for node in wflow['links'].keys():\n",
    "        if not wflow['links'][node]:\n",
    "            return node\n",
    "    raise ValueError('last node not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cif, info in d.items():\n",
    "    submission_id = info['submission_id']\n",
    "    wflow = lpad.workflows.find_one({'metadata.submission_id': submission_id}, wflows_projection)\n",
    "    if wflow['state'] != 'COMPLETED':\n",
    "        continue\n",
    "    fw_id = find_root_node(wflow)\n",
    "    task_ids = [None]\n",
    "    while 1:\n",
    "        launch_id = lpad.fireworks.find_one({'fw_id': fw_id}, {'launches': 1, '_id': 0})['launches'][-1]\n",
    "        launch = lpad.launches.find_one(\n",
    "            {'launch_id': launch_id, 'action.stored_data.task_id': {'$exists': 1}},\n",
    "            {'action.stored_data.task_id': 1, '_id': 0}\n",
    "        )\n",
    "        if launch:\n",
    "            task_ids.append(launch['action']['stored_data']['task_id'])\n",
    "        children = wflow['links'][str(fw_id)]\n",
    "        if not children:\n",
    "            break\n",
    "        fw_id = children[-1]\n",
    "    mat = db_jp.materials.find_one({'task_ids': {'$in': task_ids}}, {'task_id': 1, 'task_ids': 1, '_id': 0})\n",
    "    info['fw_id'] = fw_id\n",
    "    info['mp_id'] = mat['task_id']\n",
    "    print(d[cif])\n",
    "    #break\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout = open('mpcomplete_kitchaev_mpids.json', 'w')\n",
    "json.dump(d, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fw_ids for list of mp-ids to fix DOS offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mp_ids = ['mp-27187','mp-695866','mp-25732','mp-770957','mp-770953','mp-685168','mp-672214','mp-561549','mp-679630',\n",
    "#           'mp-7323','mp-772665','mp-17895','mp-770566','mp-25772','mp-3009','mp-625837','mp-12797','mp-28588',\n",
    "#           'mp-770887','mp-776836','mp-5185','mp-24570','mp-723049','mp-657176','mp-25766','mp-19548','mp-625823',\n",
    "#           'mp-684950','mp-557613','mp-704536','mp-722237','mp-676950']\n",
    "mp_ids = ['mp-5229']\n",
    "snlgroup_ids = db_jp.materials.find({'task_ids': {'$in': mp_ids}}).distinct('snlgroup_id')\n",
    "fw_ids_dosfix = lpad.fireworks.find({\"spec.snlgroup_id\": {'$in': snlgroup_ids}}).distinct('fw_id')\n",
    "wflows_dosfix = list(lpad.workflows.find({'nodes': {'$in': fw_ids_dosfix}}))\n",
    "fw_ids_rerun = []\n",
    "fw_ids_defuse = []\n",
    "task_ids = set()\n",
    "for wflow in wflows_dosfix:\n",
    "    print('wf:', wflow['nodes'][0])\n",
    "    fw_ids_uniform = []\n",
    "    for fw in list(lpad.fireworks.find({'fw_id': {'$in': wflow['nodes']}})):\n",
    "        if 'Uniform' in fw['spec']['task_type']:\n",
    "            fw_ids_uniform.append(fw['fw_id'])\n",
    "        elif 'Boltztrap' in fw['spec']['task_type']:\n",
    "            fw_ids_defuse.append(fw['fw_id'])\n",
    "        elif 'VASP db' in fw['spec']['task_type']:\n",
    "            print(fw['fw_id'], fw['launches'][-1])\n",
    "            launch = lpad.launches.find_one({'launch_id': fw['launches'][-1]}, {'_id': 0, 'action.stored_data': 1})\n",
    "            task_ids.add(launch['action']['stored_data'].get('task_id'))\n",
    "    if not fw_ids_uniform:\n",
    "        continue\n",
    "    fw_ids_rerun.append(max(fw_ids_uniform))\n",
    "len(fw_ids_rerun)\n",
    "fw_ids_rerun\n",
    "task_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(map(str, fw_ids_rerun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw_ids_defuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw_ids_run = []\n",
    "for wflow in lpad.workflows.find({'nodes': {'$in': fw_ids_rerun}}):\n",
    "    for fw_id, fw_state in wflow['fw_states'].items():\n",
    "        if fw_state != 'COMPLETED' and fw_state != 'DEFUSED':\n",
    "            fw_ids_run.append(fw_id)\n",
    "','.join(map(str, fw_ids_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(map(str, fw_ids_defuse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw_ids_dos_offset = []\n",
    "for doc in list(lpad.workflows.find({'nodes': {'$in': fw_ids_gga}}, {'fw_states': 1, '_id': 0})):\n",
    "    for fw_id, fw_state in doc['fw_states'].items():\n",
    "        if fw_state == 'READY' or fw_state == 'WAITING':\n",
    "            fw_ids_dos_offset.append(fw_id)\n",
    "len(fw_ids_dos_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(int, fw_ids_dos_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections for BoltzTraP builder: set to READY and update_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw_ids_vasp_db_rerun = []\n",
    "for fw_id, fw_info in fws_info.items():\n",
    "    if fw_info['launch_dir']: # GGA Uniform launch_dir exists\n",
    "        wf = lpad.workflows.find_one({'nodes': fw_id}, {'_id': 0, 'links': 1})\n",
    "        for daughter in wf['links'][str(fw_id)]:\n",
    "            fw = lpad.fireworks.find_one(\n",
    "                {'fw_id': daughter, 'spec.task_type': 'VASP db insertion'}, {'fw_id': 1, '_id': 0}\n",
    "            )\n",
    "            if fw:\n",
    "                fw_ids_vasp_db_rerun.append(fw['fw_id'])\n",
    "                break\n",
    "len(fw_ids_vasp_db_rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpad.fireworks.update_many(\n",
    "    {'fw_id': {'$in': fw_ids_vasp_db_rerun}},\n",
    "    {\"$set\":{\"state\":\"READY\", \"spec._tasks.0.update_duplicates\": True}}\n",
    ").raw_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNL and Task Collections for atomate transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('snl_tasks_atomate.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "query = {} if not data else {'task_id': {'$nin': data.keys()}}\n",
    "has_bs_piezo_dos = {'has_bandstructure': True, 'piezo': {'$exists': 1}, 'dos': {'$exists': 1}}\n",
    "#query.update(has_bs_piezo_dos)\n",
    "has_bs_dos = {'has_bandstructure': True, 'dos': {'$exists': 1}}\n",
    "query.update(has_bs_dos)\n",
    "docs = db_jp.materials.find(query, {'task_ids': 1, '_id': 0, 'task_id': 1, 'snl.snl_id': 1})\n",
    "\n",
    "for idx,doc in tqdm(enumerate(docs), total=docs.count()):\n",
    "    mpid = doc['task_id']\n",
    "    data[mpid] = {'tasks': {}}\n",
    "    if set(has_bs_piezo_dos.keys()).issubset(query.keys()):\n",
    "        data[mpid]['tags'] = ['has_bs_piezo_dos']\n",
    "    if set(has_bs_dos.keys()).issubset(query.keys()):\n",
    "        data[mpid]['tags'] = ['has_bs_dos']\n",
    "    for task_id in doc['task_ids']:\n",
    "        tasks = list(db_vasp.tasks.find({'task_id': task_id}, {'dir_name': 1, '_id': 0}))\n",
    "        if len(tasks) > 1:\n",
    "            data[mpid]['error'] = 'found {} tasks'.format(len(tasks))\n",
    "            continue\n",
    "        elif not tasks:\n",
    "            data[mpid]['error'] = 'no task found'\n",
    "            continue\n",
    "        dir_name = tasks[0]['dir_name']\n",
    "        launch_dir = os.path.join(GARDEN, dir_name)\n",
    "        if not os.path.exists(launch_dir):\n",
    "            data[mpid]['error'] = '{} not found'.format(dir_name)\n",
    "            break\n",
    "        data[mpid]['tasks'][task_id] = launch_dir\n",
    "    data[mpid]['snl_id'] = doc['snl']['snl_id']\n",
    "    if not idx%2000:\n",
    "        with open('snl_tasks_atomate.json', 'w') as f:\n",
    "            json.dump(data, f)\n",
    "        #break\n",
    "        \n",
    "with open('snl_tasks_atomate.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python2 (mpworks)",
   "language": "python",
   "name": "mpworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
